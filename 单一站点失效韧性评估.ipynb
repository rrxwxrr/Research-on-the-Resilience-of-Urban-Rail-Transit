{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adf04b47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-23T01:09:29.355274Z",
     "start_time": "2023-12-23T01:09:28.515163Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import datetime\n",
    "import networkx as nx\n",
    "import matplotlib as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import ast\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  #忽略pandas发出的无效警告\n",
    "from tqdm import tqdm #进度条库"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f02281",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-22T07:07:30.177406Z",
     "start_time": "2023-12-22T07:07:30.173417Z"
    }
   },
   "source": [
    "1.逐个节点攻击，获得单一节点失效情况下网络的韧性值，探讨一下韧性值与点度中心性、介数中心性、客流量之间的相关性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "565683f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-23T01:10:55.504566Z",
     "start_time": "2023-12-23T01:09:29.355938Z"
    }
   },
   "outputs": [],
   "source": [
    "#################################################数据集########################################################\n",
    "#地铁网络表格\n",
    "network = pd.read_csv(r'J:/IC卡-北京/地铁交通流分配/数据集/subway_network.csv',encoding = 'gbk')\n",
    "#站点编号\n",
    "stop_num = pd.read_csv(r'J:/IC卡-北京/地铁交通流分配/数据集/stop_num.csv',encoding = 'gbk')\n",
    "#客流量与路径表格\n",
    "OP = pd.read_csv(r'J:/IC卡-北京/地铁交通流分配/数据集/初始路径计算2.0/OD+Initial_Path.csv',encoding='gbk')\n",
    "OP['Path'] = OP['Path'].apply(ast.literal_eval) #将Path列的数据转换为列表，不然后面会识别不了"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0837a9cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-22T07:18:23.342852Z",
     "start_time": "2023-12-22T07:18:23.311904Z"
    }
   },
   "source": [
    "<div class=\"burk\">\n",
    "备注：因为构建网络时需要对换乘节点进行虚拟化，所以在这个会出现一个换乘站点对应多个编号。所以先按照编号逐个攻击\n",
    "节点，最后再将一个站点对应一个编号的结果进行合并，并归纳到编号数值较小的那一个编号。</div><i class=\"fa fa-lightbulb-o \"></i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89e69a23",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-23T01:10:55.512062Z",
     "start_time": "2023-12-23T01:10:55.504566Z"
    }
   },
   "outputs": [],
   "source": [
    "#定义函数，提取相关记录\n",
    "#值得注意的是，此处的筛选的记录不一定是刚好能在节点失效时段时的碰到的记录\n",
    "def related_records(df, target_list): #输入的是待处理表格、节点修复顺序列表\n",
    "    target_list = [str(x) for x in target_list]  # 将目标列表中的元素转换为字符串类型\n",
    "    # 筛选出 f_timestamp 列中数据小于等于 1557824400 的行\n",
    "    df1 = df.loc[df['f_timestamp'] < 1557824400] #出发时间点小于时段终点的记录\n",
    "    # 再筛选出 t_timestamp 列中数据大于等于 1557817200 的行\n",
    "    df2 = df1.loc[df['t_timestamp'] > 1557817200] #到达时间点大于时间段起点的记录，df2就是符合时间范围的记录\n",
    "    #接下来筛选是否经过失效站点的记录\n",
    "    condition = df['Path'].apply(lambda x: any(str(i) in str(x) for i in target_list)) #加一个经过失效站点的条件                                                                     \n",
    "    result_df = df2[condition] #符合条件的存储为result_df\n",
    "    result_df1 =  df2.loc[~condition] #不符合条件的存储为result_df1\n",
    "    return result_df,result_df1 #返回result_df是为了减少后期寻找路径的计算量，返回没被筛选的是计算韧性值时用到"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a68a030e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-23T01:10:55.526183Z",
     "start_time": "2023-12-23T01:10:55.512864Z"
    }
   },
   "outputs": [],
   "source": [
    "#定义节点失效时段字典生成函数\n",
    "def generate_dict(target_list, t_start, duration):  #传入失效节点修复序列，起始时间节点，节点修复所需时间\n",
    "    result_dict = {}\n",
    "    x = 0\n",
    "    for num in target_list:\n",
    "        x = x + 1\n",
    "        result_dict[num] = (t_start, t_start + x * duration)\n",
    "    return result_dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b600553",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-23T01:10:55.539601Z",
     "start_time": "2023-12-23T01:10:55.526183Z"
    }
   },
   "outputs": [],
   "source": [
    "#定义函数计算到达失效站点的编号、时间、失效站点前一个站点编号、到达失效站点前一个站点时间\n",
    "def calculate_time(row): #输入的是每一行的表格数据\n",
    "    node_list = row['Path'] #路径的节点列表\n",
    "    travel_time = row['Travel_time'] #路径的出行时间\n",
    "    f_timestamp = row['f_timestamp'] #该出行记录的起始时刻\n",
    "    total_nodes = len(node_list) #获取路径的节点个数也就是路径长度\n",
    "    for i, node in enumerate(node_list): #i是该节点在列表中的索引，node就是该节点的编号\n",
    "        if node in target_list and i != 0:  # 判断该节点是否是失效节点，并且并非是起点，保证可以返回前一个节点\n",
    "            prev_node = node_list[i-1] #Path返回符合条件节点的前一个节点\n",
    "#             if prev_node in target_list:  # 判断失效节点的前一个节点是否也是失效节点\n",
    "#                 continue\n",
    "            sx_start, sx_end = stop_sx_range[node] #获取节点的失效时间的起终点时刻\n",
    "            node_arrival = f_timestamp + travel_time*(i/total_nodes) #到达该失效节点的时刻\n",
    "            node_before_arrival = f_timestamp + travel_time*((i-1)/total_nodes) #到达该失效节点前一个节点的时刻\n",
    "            if sx_start <= node_arrival <= sx_end:#如果节点到达时刻正好在失效时段\n",
    "                fail_stop = node #失效节点就是该节点\n",
    "                un_stop = prev_node #失效节点的前一个节点\n",
    "                time_fail = int(node_arrival +180) #到达失效节点的时间\n",
    "                time_before = int(node_before_arrival + 180) #到达失效节点前一个节点的时间\n",
    "                return pd.Series({'fail_stop': fail_stop, 'un_stop': un_stop, 'time_fail': time_fail, 'time_before': time_before})\n",
    "        elif node in target_list and i == 0:\n",
    "            prev_node = node #否则失效节点的前一个节点也是其自身\n",
    "            sx_start, sx_end = stop_sx_range[node] #获取节点的失效时间的起终点时刻\n",
    "            node_arrival = f_timestamp\n",
    "            if sx_start <= node_arrival <= sx_end:\n",
    "                fail_stop = node #失效节点就是该节点\n",
    "                un_stop = prev_node #失效节点的前一个节点\n",
    "                time_fail = f_timestamp\n",
    "                time_before = f_timestamp\n",
    "                return pd.Series({'fail_stop': fail_stop, 'un_stop': un_stop, 'time_fail': time_fail, 'time_before': time_before})\n",
    "    # Return NaN for fail_stop, un_stop, time_fail, and time_before columns if matching node is not found\n",
    "    return pd.Series({'fail_stop':None, 'un_stop':None, 'time_fail':None, 'time_before':None})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cfbd897",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-23T01:10:55.553220Z",
     "start_time": "2023-12-23T01:10:55.539601Z"
    }
   },
   "outputs": [],
   "source": [
    "#移除网络中的失效节点\n",
    "def remove_failed_nodes(network, failed_nodes):\n",
    "    network_xf = network[~network['Source_num'].isin(failed_nodes) & ~network['Target_num'].isin(failed_nodes)] #~表示取反\n",
    "    return network_xf #返回去除失效站点的网络\n",
    "\n",
    "# 计算最短路径的权重之和\n",
    "def calculate_shortest_path_weight(G, un_stop, target_num):#计算最短路的出行时间,输入的是网络，失效站点的前一个站点，原始终点\n",
    "    try:\n",
    "        if un_stop not in G.nodes or target_num not in G.nodes:\n",
    "            raise ValueError(\"起点或终点不在网络中\")\n",
    "        path = nx.shortest_path(G, source=un_stop, target=target_num, weight='weight')\n",
    "        weight_sum = nx.path_weight(G, path, weight='weight') + 300 #加上疏散时间\n",
    "        return weight_sum\n",
    "    except (nx.NetworkXNoPath, ValueError) as e:\n",
    "        return None\n",
    "\n",
    "def Remaining_path(start_num, end_num, lst):#输入任点1、点2，路径列表，输出点1和点2之间的路径列表\n",
    "    start_idx = lst.index(start_num)\n",
    "    end_idx = lst.index(end_num)\n",
    "    if start_idx > end_idx:\n",
    "        start_idx, end_idx = end_idx, start_idx\n",
    "    return lst[start_idx:end_idx+1]\n",
    "    \n",
    "# 计算 List 列给定路径的权重之和并扩大\n",
    "def calculate_list_path_weight(G, un_stop, target_num, list_data):#这是计算换乘公交的剩余路径出行时间\n",
    "    path = Remaining_path(un_stop,target_num,list_data) #剩余的路径通过上面定的函数来求得\n",
    "    weight_sum = nx.path_weight(G, path,weight='weight') #计算剩余路径的长度\n",
    "    return weight_sum * 2.51 #按照公交的出行时间是地铁的出行时间的2.51倍来计算，公交15，地铁44.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed6b000b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-23T01:10:55.566511Z",
     "start_time": "2023-12-23T01:10:55.553220Z"
    }
   },
   "outputs": [],
   "source": [
    "#定义网络生成函数\n",
    "def creat_network(network): #创建网络生成函数，输入不同的network文件会生成对应的网络，生成初始表格只需要输入初始网络表格数据\n",
    "    # 创建空的图\n",
    "    G = nx.Graph()\n",
    "    # 添加节点和边\n",
    "    for _, row in network.iterrows():\n",
    "        src = row['Source_num']\n",
    "        dst = row['Target_num']\n",
    "        time = row['Travel_time']\n",
    "        src_lon = row['Source_lon']\n",
    "        src_lat = row['Source_lat']\n",
    "        dst_lon = row['Target_lon']\n",
    "        dst_lat = row['Target_lat']   \n",
    "        # 添加节点\n",
    "        G.add_node(src, pos=(src_lon, src_lat))\n",
    "        G.add_node(dst, pos=(dst_lon, dst_lat))\n",
    "        # 添加边\n",
    "        G.add_edge(src, dst, weight=time)\n",
    "    # 设置节点位置\n",
    "    pos = nx.get_node_attributes(G, 'pos')\n",
    "    # 设置边权重\n",
    "    labels = nx.get_edge_attributes(G, 'weight')\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d741c6ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-23T01:10:55.577731Z",
     "start_time": "2023-12-23T01:10:55.566511Z"
    }
   },
   "outputs": [],
   "source": [
    "#####查找失效站点，并返回失效站点列表\n",
    "def find_failed_nodes(time_before, dict1):\n",
    "    failed_nodes = []\n",
    "    for key, value in dict1.items():\n",
    "        if value[0] <= time_before <= value[1]:#如果失效节点正好在失效时段之内，那么就返回失效站点编号\n",
    "            failed_nodes.append(key)\n",
    "    return failed_nodes\n",
    "\n",
    "# 移除网络表格中失效节点对应的行，也就是在网络中删除失效节点\n",
    "def remove_failed_nodes(network,target_list):\n",
    "    network_xf = network[~network['Source_num'].isin(target_list) & ~network['Target_num'].isin(target_list)] #~表示取反\n",
    "    return network_xf #返回去除失效站点的网络\n",
    "\n",
    "# 计算最短路径的权重之和\n",
    "def calculate_shortest_path_weight(G, un_stop, target_num):#计算最短路的出行时间,输入的是网络，失效站点的前一个站点，原始终点\n",
    "    try:\n",
    "        if un_stop not in G.nodes or target_num not in G.nodes:\n",
    "            raise ValueError(\"起点或终点不在网络中\")\n",
    "        path = nx.shortest_path(G, source=un_stop, target=target_num, weight='weight')\n",
    "        weight_sum = nx.path_weight(G, path, weight='weight') + 300 #加上疏散时间\n",
    "        return weight_sum\n",
    "    except (nx.NetworkXNoPath, ValueError) as e:\n",
    "        return None\n",
    "\n",
    "def Remaining_path(start_num, end_num, lst):#输入任点1、点2，路径列表，输出点1和点2之间的路径列表\n",
    "    start_idx = lst.index(start_num)\n",
    "    end_idx = lst.index(end_num)\n",
    "    if start_idx > end_idx:\n",
    "        start_idx, end_idx = end_idx, start_idx\n",
    "    return lst[start_idx:end_idx+1]\n",
    "    \n",
    "# 计算 List 列给定路径的权重之和并扩大\n",
    "def calculate_list_path_weight(G, un_stop, target_num, list_data):#这是计算换乘公交的剩余路径出行时间\n",
    "    path = Remaining_path(un_stop,target_num,list_data) #剩余的路径通过上面定的函数来求得\n",
    "    weight_sum = nx.path_weight(G, path,weight='weight') #计算剩余路径的长度\n",
    "    return weight_sum * 2.51 #按照公交的出行时间是地铁的出行时间的2.51倍来计算，公交15，地铁44.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e96e1478",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-23T01:10:55.591143Z",
     "start_time": "2023-12-23T01:10:55.577731Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_weight(group):\n",
    "    first_value = group.iloc[0] #选取每一组中的第一行数据，进行计算\n",
    "    un_stop = first_value['un_stop']\n",
    "    target_num = first_value['Target_num']\n",
    "    list_data = first_value['Path']\n",
    "    time_before = first_value['time_before']\n",
    "    failed_nodes  = find_failed_nodes(time_before, stop_sx_range)\n",
    "    network_sx = remove_failed_nodes(network,failed_nodes)\n",
    "    G = creat_network(network_sx)\n",
    "    weight_sum = calculate_shortest_path_weight(G, un_stop, target_num)\n",
    "    if weight_sum is None:\n",
    "        G = G0\n",
    "        weight_sum = calculate_list_path_weight(G, un_stop, target_num, list_data)\n",
    "    group['time_part2'] = weight_sum #给每个小组的time_part2列赋值\n",
    "    return group\n",
    "#调用函数\n",
    "#Related_records = Related_records.groupby(['Target_num', 'un_stop']).apply(calculate_weight) # 需要传入函数calculate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7785c62a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-23T03:10:40.857946Z",
     "start_time": "2023-12-23T02:16:09.955724Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n"
     ]
    }
   ],
   "source": [
    "data = [] #定义一个空列表用于存储计算生成的性能值和其对应的站点编号\n",
    "t_start = 1557817200 #要计算的时段起点\n",
    "duration = 720 #计算的周期\n",
    "G0 = creat_network(network)\n",
    "\n",
    "for failed_node in range(340,395): #遍历1-395，左闭右开\n",
    "    target_list = [500,501,502,503,504,505,506,507,508] #在循环里面新建列表，每一个循环清空一次列表，这样使得列表里只有该次遍历的节点\n",
    "    target_list.append(failed_node) #广义上的失效列表\n",
    "    \n",
    "    stop_sx_range = generate_dict(target_list=target_list, t_start=t_start, duration=duration) #调用自定义函数\n",
    "    Related_records,Unrelated_records = related_records(OP, target_list) #获取相关记录\n",
    "    if Related_records.empty:\n",
    "        q = 1\n",
    "    else:\n",
    "        len(Related_records),len(Unrelated_records)\n",
    "        All_size = len(Related_records) + len(Unrelated_records)\n",
    "    \n",
    "        Related_records[['fail_stop', 'un_stop', 'time_fail', 'time_before']] = Related_records.apply(calculate_time, axis=1)\n",
    "        #起点就是失效站点，算作直接换乘公交的群体\n",
    "        Group_tobus = Related_records[Related_records['fail_stop'] == Related_records['un_stop']]\n",
    "        time_tobus = Group_tobus['Travel_time'].sum()\n",
    "        delay_Grouptobus = 1.51*time_tobus #起点就失效的乘客换乘公交产生的延误\n",
    "    \n",
    "        Related_records = Related_records[~Related_records['fail_stop'].isna()] #isnull和isna是有区别的，筛选经过失效站点的出行记录用于计算，减少计算量\n",
    "        Affected_size = len(Related_records) #这里的Related_records已经是筛选出有失效站点记录的表格了\n",
    "        Group_normal = Related_records[Related_records['fail_stop'].isna()] #不经过失效站点的出行记录，只要计算总出行时间和人数就可以\n",
    "        #计算df2的参数N\n",
    "        normal_trip = len(Group_normal)\n",
    "        normal_time = Group_normal['Travel_time'].sum()\n",
    "    \n",
    "        Related_records = Related_records.groupby(['Target_num', 'un_stop']).apply(calculate_weight) # 需要传入函数calculate\n",
    "\n",
    "        Related_records['time_part1'] = Related_records['time_before'] - Related_records['f_timestamp']\n",
    "        #计算出等待人群的等待时间\n",
    "        Related_records['wait_duration'] = Related_records['time_before'].apply(lambda x: 3600 - ((x - 1557817200) % 3600) if ((x - 1557817200) % 3600) >= 3300 else None)\n",
    "        # 填充缺失值为0，计算更新计算后的出行时间表格\n",
    "        Related_records['Travel_time_now'] = Related_records['time_part1'].fillna(0) + Related_records['time_part2'].fillna(0) + Related_records['wait_duration'].fillna(0)\n",
    "        conditions = (Related_records['Travel_time_now'] == 0)\n",
    "        Related_records.loc[conditions, 'Travel_time_now'] = Related_records.loc[conditions, 'Travel_time']\n",
    "    \n",
    "        #计算延误指数和中断指数\n",
    "        Delay_Index = (Related_records['Travel_time_now'].sum() - Related_records['Travel_time'].sum() + delay_Grouptobus)/(Unrelated_records['Travel_time'].sum() + Related_records['Travel_time'].sum() + normal_time + time_tobus)\n",
    "        Interruption_Index = Affected_size/All_size\n",
    "    \n",
    "        #标准化延误指数和中断指数\n",
    "        Standard_Delay_Index = Delay_Index/1.51\n",
    "        Standard_Interruption_Index = Interruption_Index\n",
    "\n",
    "        #计算性能指标\n",
    "        a = 0.5 #权重值，取值在0到1之间\n",
    "        q = 1-(a *  Standard_Delay_Index + ( 1-a )* Standard_Interruption_Index)\n",
    "\n",
    "    data.append((failed_node, q))\n",
    "    print(failed_node)\n",
    "\n",
    "df_Q = pd.DataFrame(data, columns=['stop', 'Q'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "44932ec3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-23T03:10:40.879536Z",
     "start_time": "2023-12-23T03:10:40.859942Z"
    }
   },
   "outputs": [],
   "source": [
    "df_Q.to_csv('J:/IC卡-北京/地铁交通流分配/数据集/早高峰单点攻击韧性2.csv',encoding = 'gbk', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c432e62c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2dc581",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f5d4ab77",
   "metadata": {},
   "source": [
    "2.同一个节点，攻击时长不同，看攻击时长对网络的影响，这里主要变化的量是客流量的变化，可以看看网络韧性与交通流变化之间相关性"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
